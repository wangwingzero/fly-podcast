name: daily-digest

on:
  schedule:
    - cron: "0 19 * * *" # Beijing 03:00
  workflow_dispatch:

env:
  TZ: Asia/Shanghai
  DRY_RUN: ${{ vars.DRY_RUN || 'true' }}
  TARGET_ARTICLE_COUNT: ${{ vars.TARGET_ARTICLE_COUNT || '10' }}
  DOMESTIC_RATIO: ${{ vars.DOMESTIC_RATIO || '0.0' }}
  QUALITY_THRESHOLD: ${{ vars.QUALITY_THRESHOLD || '80' }}
  ALLOW_GOOGLE_REDIRECT_CITATION: ${{ vars.ALLOW_GOOGLE_REDIRECT_CITATION || 'false' }}
  LLM_API_KEY: ${{ secrets.LLM_API_KEY }}
  LLM_BASE_URL: ${{ vars.LLM_BASE_URL || 'https://api.agentify.top/v1/chat/completions' }}
  LLM_MODEL: ${{ vars.LLM_MODEL || 'openai/gpt-oss-120b' }}
  LLM_MAX_TOKENS: ${{ vars.LLM_MAX_TOKENS || '6000' }}
  LLM_TEMPERATURE: ${{ vars.LLM_TEMPERATURE || '0.1' }}
  WECHAT_ENABLE_PUBLISH: ${{ vars.WECHAT_ENABLE_PUBLISH || 'false' }}
  WECHAT_APP_ID: ${{ secrets.WECHAT_APP_ID }}
  WECHAT_APP_SECRET: ${{ secrets.WECHAT_APP_SECRET }}
  WECHAT_AUTHOR: ${{ vars.WECHAT_AUTHOR || '' }}
  WECHAT_THUMB_MEDIA_ID: ${{ secrets.WECHAT_THUMB_MEDIA_ID }}
  WECHAT_PROXY: ${{ vars.WECHAT_PROXY || '' }}
  UNSPLASH_ACCESS_KEY: ${{ secrets.UNSPLASH_ACCESS_KEY }}
  UNSPLASH_ACCESS_KEY_2: ${{ secrets.UNSPLASH_ACCESS_KEY_2 }}
  PIXABAY_API_KEY: ${{ secrets.PIXABAY_API_KEY }}
  IMAGE_GEN_API_KEY: ${{ secrets.IMAGE_GEN_API_KEY }}
  IMAGE_GEN_BASE_URL: ${{ vars.IMAGE_GEN_BASE_URL || '' }}
  IMAGE_GEN_MODEL: ${{ vars.IMAGE_GEN_MODEL || '' }}
  IMAGE_GEN_BACKUP_API_KEY: ${{ secrets.IMAGE_GEN_BACKUP_API_KEY }}
  IMAGE_GEN_BACKUP_BASE_URL: ${{ vars.IMAGE_GEN_BACKUP_BASE_URL || '' }}
  IMAGE_GEN_BACKUP_MODEL: ${{ vars.IMAGE_GEN_BACKUP_MODEL || '' }}
  WEB_DIGEST_BASE_URL: ${{ vars.WEB_DIGEST_BASE_URL || '' }}
  COPYRIGHT_NOTICE_URL: ${{ vars.COPYRIGHT_NOTICE_URL || '' }}
  ALERT_WEBHOOK_URL: ${{ secrets.ALERT_WEBHOOK_URL }}
  EMAIL_USER: ${{ secrets.EMAIL_USER }}
  EMAIL_PASS: ${{ secrets.EMAIL_PASS }}

concurrency:
  group: flying-podcast-daily-digest
  cancel-in-progress: false

jobs:
  daily-digest:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - run: pip install -r requirements.txt

      - name: Download recent published history from R2
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
          R2_BUCKET: ${{ vars.R2_BUCKET || 'flying-podcast' }}
        run: |
          mkdir -p data/history
          aws s3 cp "s3://${R2_BUCKET}/history/recent_published.json" data/history/recent_published.json \
            --endpoint-url "${R2_ENDPOINT}" || echo "No history file yet, first run"

      - name: "Stage 1/6: Ingest"
        run: python run.py ingest --date "$(date +%F)"

      - name: "Stage 2/6: Rank"
        run: python run.py rank --date "$(date +%F)"

      - name: "Stage 3/6: Compose"
        run: python run.py compose --date "$(date +%F)"

      - name: "Stage 4/6: Verify"
        run: python run.py verify --date "$(date +%F)"

      - name: "Stage 5/6: Publish"
        run: python run.py publish --date "$(date +%F)"

      - name: Upload web digest to R2
        if: hashFiles('data/output/web_*.html') != ''
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
          R2_BUCKET: ${{ vars.R2_BUCKET || 'flying-podcast' }}
        run: |
          aws s3 cp data/output/ "s3://${R2_BUCKET}/digest/" \
            --endpoint-url "${R2_ENDPOINT}" \
            --recursive \
            --exclude "*" --include "web_*.html" \
            --content-type "text/html; charset=utf-8" \
            --cache-control "public, max-age=86400"
          aws s3 cp static/copyright.html "s3://${R2_BUCKET}/digest/copyright.html" \
            --endpoint-url "${R2_ENDPOINT}" \
            --content-type "text/html; charset=utf-8" \
            --cache-control "public, max-age=604800"
          aws s3 cp static/beian_icon.png "s3://${R2_BUCKET}/digest/beian_icon.png" \
            --endpoint-url "${R2_ENDPOINT}" \
            --content-type "image/png" \
            --cache-control "public, max-age=2592000"

      - name: Upload recent published history to R2
        if: hashFiles('data/history/recent_published.json') != ''
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
          R2_BUCKET: ${{ vars.R2_BUCKET || 'flying-podcast' }}
        run: |
          aws s3 cp data/history/recent_published.json "s3://${R2_BUCKET}/history/recent_published.json" \
            --endpoint-url "${R2_ENDPOINT}" \
            --content-type "application/json"

      - name: "Stage 6/6: Notify"
        run: python run.py notify --date "$(date +%F)"

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: daily-digest-${{ github.run_id }}
          path: |
            data/raw/*.json
            data/processed/*.json
            data/output/publish_*.json
