name: podcast-from-pdf

on:
  push:
    branches: [main]
    paths:
      - "podcast_pdfs/**.pdf"
  workflow_dispatch:
    inputs:
      greeting:
        description: "Extra prompt for dialogue (e.g. holiday greeting)"
        required: false
        default: ""
      pdf_filter:
        description: "Only process PDFs matching this keyword (empty = all)"
        required: false
        default: ""

env:
  TZ: Asia/Shanghai

concurrency:
  group: podcast-from-pdf
  cancel-in-progress: false

jobs:
  # ── Job 1: Discover PDFs and build matrix ──────────────────
  find-pdfs:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.build-matrix.outputs.matrix }}
      has_pdfs: ${{ steps.build-matrix.outputs.has_pdfs }}
      date: ${{ steps.build-matrix.outputs.date }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Build PDF matrix
        id: build-matrix
        run: |
          DATE=$(TZ=Asia/Shanghai date +%F)
          echo "date=$DATE" >> "$GITHUB_OUTPUT"

          FILTER="${{ github.event.inputs.pdf_filter }}"
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            PDFS=$(find podcast_pdfs -maxdepth 1 -name "*.pdf" -type f 2>/dev/null || true)
          else
            PDFS=$(git diff --name-only --diff-filter=A ${{ github.event.before }} ${{ github.sha }} -- 'podcast_pdfs/*.pdf' || true)
          fi
          if [ -n "$FILTER" ] && [ -n "$PDFS" ]; then
            PDFS=$(echo "$PDFS" | grep -i "$FILTER" || true)
          fi
          if [ -z "$PDFS" ]; then
            echo "No PDFs to process"
            echo "has_pdfs=false" >> "$GITHUB_OUTPUT"
            echo 'matrix={"pdf":[]}' >> "$GITHUB_OUTPUT"
          else
            echo "PDFs to process:"
            echo "$PDFS"
            # Build JSON array for matrix
            JSON=$(echo "$PDFS" | jq -R -s -c 'split("\n") | map(select(length > 0))')
            echo "matrix={\"pdf\":$JSON}" >> "$GITHUB_OUTPUT"
            echo "has_pdfs=true" >> "$GITHUB_OUTPUT"
          fi

  # ── Job 2: Generate each podcast in parallel ───────────────
  generate:
    needs: find-pdfs
    if: needs.find-pdfs.outputs.has_pdfs == 'true'
    runs-on: ubuntu-latest
    strategy:
      matrix: ${{ fromJson(needs.find-pdfs.outputs.matrix) }}
      fail-fast: false
      max-parallel: 5
    env:
      LLM_API_KEY: ${{ secrets.LLM_API_KEY }}
      LLM_BASE_URL: ${{ vars.LLM_BASE_URL || 'https://api.agentify.top/v1/chat/completions' }}
      LLM_MODEL: ${{ vars.LLM_MODEL || 'claude-sonnet-4-6' }}
      LLM_MAX_TOKENS: ${{ vars.LLM_MAX_TOKENS || '6000' }}
      LLM_TEMPERATURE: ${{ vars.LLM_TEMPERATURE || '0.1' }}
      DASHSCOPE_API_KEY: ${{ secrets.DASHSCOPE_API_KEY }}
      QWEN_TTS_URL: ${{ vars.QWEN_TTS_URL || 'http://localhost:8825' }}
      PODCAST_GREETING: ${{ github.event.inputs.greeting || '' }}
      UNSPLASH_ACCESS_KEY: ${{ secrets.UNSPLASH_ACCESS_KEY }}
      UNSPLASH_ACCESS_KEY_2: ${{ secrets.UNSPLASH_ACCESS_KEY_2 }}
      PIXABAY_API_KEY: ${{ secrets.PIXABAY_API_KEY }}
      IMAGE_GEN_API_KEY: ${{ secrets.IMAGE_GEN_API_KEY }}
      IMAGE_GEN_BASE_URL: ${{ vars.IMAGE_GEN_BASE_URL || '' }}
      IMAGE_GEN_MODEL: ${{ vars.IMAGE_GEN_MODEL || '' }}
      IMAGE_GEN_BACKUP_API_KEY: ${{ secrets.IMAGE_GEN_BACKUP_API_KEY }}
      IMAGE_GEN_BACKUP_BASE_URL: ${{ vars.IMAGE_GEN_BACKUP_BASE_URL || '' }}
      IMAGE_GEN_BACKUP_MODEL: ${{ vars.IMAGE_GEN_BACKUP_MODEL || '' }}
      R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
      R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
      R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
      R2_BUCKET: ${{ vars.R2_BUCKET || 'ccar-pdfs' }}
      R2_DOMAIN: ${{ vars.R2_DOMAIN || 'ccar.hudawang.cn' }}
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          sudo apt-get update && sudo apt-get install -y ffmpeg

      - name: Generate podcast
        run: |
          PDF="${{ matrix.pdf }}"
          DATE="${{ needs.find-pdfs.outputs.date }}"
          echo "=========================================="
          echo "Processing: $PDF"
          echo "=========================================="
          python run.py podcast --date "$DATE" --pdf "$PDF"

      - name: Upload podcast output
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: podcast-${{ strategy.job-index }}
          path: data/output/podcast/

  # ── Job 3: Collect results, upload R2, publish WeChat ──────
  finalize:
    needs: [find-pdfs, generate]
    if: always() && needs.find-pdfs.outputs.has_pdfs == 'true'
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Download all podcast artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: podcast-*
          path: data/output/podcast/
          merge-multiple: true

      - name: Upload podcasts to R2
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
          R2_BUCKET: ${{ vars.R2_BUCKET || 'ccar-pdfs' }}
        run: |
          if [ -d data/output/podcast ]; then
            echo "Uploading podcast files to R2..."
            aws s3 sync data/output/podcast/ "s3://${R2_BUCKET}/podcast/" \
              --endpoint-url "${R2_ENDPOINT}"
            echo "Upload complete"
          else
            echo "No podcast output directory found"
          fi

      - name: Publish podcast drafts to WeChat
        continue-on-error: true
        env:
          DRY_RUN: "false"
          WECHAT_ENABLE_PUBLISH: "true"
          WECHAT_APP_ID: ${{ secrets.WECHAT_APP_ID }}
          WECHAT_APP_SECRET: ${{ secrets.WECHAT_APP_SECRET }}
          WECHAT_THUMB_MEDIA_ID: ${{ secrets.WECHAT_THUMB_MEDIA_ID }}
          WECHAT_PROXY: ${{ vars.WECHAT_PROXY || '' }}
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }}
          LLM_BASE_URL: ${{ vars.LLM_BASE_URL || 'https://api.agentify.top/v1/chat/completions' }}
          LLM_MODEL: ${{ vars.LLM_MODEL || 'claude-sonnet-4-6' }}
        run: |
          DATE="${{ needs.find-pdfs.outputs.date }}"
          python run.py publish-podcast --date "$DATE"

      - name: Clean up processed PDFs
        run: |
          if ls podcast_pdfs/*.pdf 1>/dev/null 2>&1; then
            rm podcast_pdfs/*.pdf
            git config user.name "github-actions[bot]"
            git config user.email "github-actions[bot]@users.noreply.github.com"
            git add podcast_pdfs/
            git commit -m "chore: remove processed podcast PDFs [skip ci]" || echo "Nothing to commit"
            git push
          else
            echo "No PDFs to clean up"
          fi

      - name: Upload combined artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: podcast-output-${{ github.run_id }}
          path: data/output/podcast/
