name: podcast-from-pdf

on:
  push:
    branches: [main]
    paths:
      - "podcast_pdfs/**.pdf"
  workflow_dispatch:

env:
  TZ: Asia/Shanghai
  LLM_API_KEY: ${{ secrets.LLM_API_KEY }}
  LLM_BASE_URL: ${{ vars.LLM_BASE_URL || 'https://api.agentify.top/v1/chat/completions' }}
  LLM_MODEL: ${{ vars.LLM_MODEL || 'openai/gpt-oss-120b' }}
  LLM_MAX_TOKENS: ${{ vars.LLM_MAX_TOKENS || '6000' }}
  LLM_TEMPERATURE: ${{ vars.LLM_TEMPERATURE || '0.1' }}
  DASHSCOPE_API_KEY: ${{ secrets.DASHSCOPE_API_KEY }}
  UNSPLASH_ACCESS_KEY: ${{ secrets.UNSPLASH_ACCESS_KEY }}
  UNSPLASH_ACCESS_KEY_2: ${{ secrets.UNSPLASH_ACCESS_KEY_2 }}
  PIXABAY_API_KEY: ${{ secrets.PIXABAY_API_KEY }}
  IMAGE_GEN_API_KEY: ${{ secrets.IMAGE_GEN_API_KEY }}
  IMAGE_GEN_BASE_URL: ${{ vars.IMAGE_GEN_BASE_URL || '' }}
  IMAGE_GEN_MODEL: ${{ vars.IMAGE_GEN_MODEL || '' }}
  IMAGE_GEN_BACKUP_API_KEY: ${{ secrets.IMAGE_GEN_BACKUP_API_KEY }}
  IMAGE_GEN_BACKUP_BASE_URL: ${{ vars.IMAGE_GEN_BACKUP_BASE_URL || '' }}
  IMAGE_GEN_BACKUP_MODEL: ${{ vars.IMAGE_GEN_BACKUP_MODEL || '' }}

concurrency:
  group: podcast-from-pdf
  cancel-in-progress: false

jobs:
  generate:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          sudo apt-get update && sudo apt-get install -y ffmpeg

      - name: Find new PDFs from this push
        id: find-pdfs
        run: |
          # Detect newly added PDFs via git diff
          ADDED=$(git diff --name-only --diff-filter=A ${{ github.event.before }} ${{ github.sha }} -- 'podcast_pdfs/**.pdf' || true)
          if [ -z "$ADDED" ]; then
            echo "No new PDFs in this push"
            echo "has_pdfs=false" >> "$GITHUB_OUTPUT"
          else
            echo "New PDFs:"
            echo "$ADDED"
            # Save list to file for later steps
            echo "$ADDED" > /tmp/new_pdfs.txt
            echo "has_pdfs=true" >> "$GITHUB_OUTPUT"
          fi

      - name: Generate podcasts
        if: steps.find-pdfs.outputs.has_pdfs == 'true'
        run: |
          DATE=$(TZ=Asia/Shanghai date +%F)
          SUCCESS=0
          FAIL=0
          while IFS= read -r pdf; do
            [ -f "$pdf" ] || continue
            echo "=========================================="
            echo "Processing: $pdf"
            echo "=========================================="
            if python run.py podcast --date "$DATE" --pdf "$pdf"; then
              SUCCESS=$((SUCCESS + 1))
            else
              echo "::warning::Failed to process: $pdf"
              FAIL=$((FAIL + 1))
            fi
          done < /tmp/new_pdfs.txt
          echo "Done: $SUCCESS succeeded, $FAIL failed"
          if [ $SUCCESS -eq 0 ] && [ $FAIL -gt 0 ]; then
            echo "::error::All PDFs failed to process"
            exit 1
          fi

      - name: Upload podcasts to R2
        if: steps.find-pdfs.outputs.has_pdfs == 'true'
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
          R2_BUCKET: ${{ vars.R2_BUCKET || 'flying-podcast' }}
        run: |
          if [ -d data/output/podcast ]; then
            echo "Uploading podcast files to R2..."
            aws s3 sync data/output/podcast/ "s3://${R2_BUCKET}/podcast/" \
              --endpoint-url "${R2_ENDPOINT}"
            echo "Upload complete"
          else
            echo "No podcast output directory found"
          fi

      - name: Upload artifacts
        if: always() && steps.find-pdfs.outputs.has_pdfs == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: podcast-output-${{ github.run_id }}
          path: data/output/podcast/
